# Electron ID tune0.yml

MAXEVENTS: 99999999

rngseed: 123456                # Fixed seed for training data mixing
inputvar: 'CMSSW_MVA_ID_ORIG'  # Input variables, implemented under mvavars.py
targetfunc: 'target_standard'  # Training target, implemented under targets.py
cutfunc: 'cut_standard'        # Basic cuts,      implemented under cuts.py
frac: 0.9                      # Train/validate/test split fraction
varnorm: 'zscore'              # Variable normalization: 'zscore', 'madscore', 'none'


# Imputation
imputation_param:
  active: true                 # True / False
  var: 'CMSSW_MVA_ID_ORIG'     # Array of variables to be imputated
  algorithm: 'constant'        # Algorithm type: 'constant', iterative' (vector), knn' (vector), 'mean' (scalar), 'median' (scalar)
  fill_value: 0                # For constant imputation
  knn_k: 8                     # Number of nearest neighbours considered
  values: [-999, -666, -10]    # Special values which indicate the need for imputation


## Outlier protection in the training phase
outlier_param:
  algo: 'truncate'   # algorithm: 'truncate', 'none'
  qmin: 0.01         # in [0,100] 
  qmax: 99.9         # in [0,100]


## Reweighting setup in the training phase
reweight_param:
  mode: 'background'           # 'none', 'signal', 'background'
  algo: '2D'
  bins_pt:  [0.0, 300.0, 1000] # Make sure the bounds cover the phase space
  bins_eta: [-3.1, 3.1,   100] # 
  max_reg: 50.0                # maxweight regularization


## Pure plotting setup
plot_param:
  basic_on:    false
  contours_on: false
  
  # (eta,pt)-binned plots
  pt_edges:  [0, 0.75, 1.0, 1.25, 1.5, 1.75, 2.5, 4.0, 10, 10000]
  eta_edges: [-10, -2.5, -1.5, -0.75, 0.0, 0.75, 1.5, 2.5, 10]



# ========================================================================
## Classifier setup
# ========================================================================

# Factorized Likelihood Ratio
flr_param:
  active: true
  label: 'FLR'
  
  nbins: 60
  qmin:  0.5 # in [0,100]
  qmax: 99.5 # in [0,100]


# XGBoost
# https://xgboost.readthedocs.io/en/latest/parameter.html
xgb_param:
  active: true
  label: 'XGB'
  
  # general parameters
  booster: 'gbtree'
  num_boost_round: 50 # Number of epochs
  n_gpus: 0
  
  # booster parameters
  n_estimators: 2000
  learning_rate: 0.1
  gamma: 0.0
  max_depth: 15
  min_child_weight: 1.0
  max_delta_step: 0
  subsample: 1.0
  colsample_bytree:  1
  colsample_bylevel: 1
  colsample_bynode:  1
  reg_lambda: 2.0 # L2 regularization
  reg_alpha: 0    # L1 regularization
  scale_pos_weight: 1
    
  # learning task parameters
  objective: 'binary:logistic'     #
  eval_metric: ['auc', 'logloss']  # for evaluation


# Logistic Regression (convex algorithm = global optimum guarantee)
mlgr_param:
  active: true
  label:  'MLGR'

  lossfunc: 'cross_entropy' # cross_entropy, focal_entropy
  gamma: 2                  # focal_entropy exponent
  optimizer: 'Adam'

  epochs: 30
  batch_size: 512
  learning_rate: 0.003
  device: 'auto'            # alternative 'cpu:0', 'cuda:0'


# XTX classifier
xtx_param:
  active: false
  label:  'XTX'

  lossfunc: 'cross_entropy' # cross_entropy, focal_entropy
  gamma: 3                  # focal loss exponent
  optimizer: 'Adam'
  
  epochs: 50
  batch_size: 512
  learning_rate: 0.003
  device: 'auto'            # alternative 'cpu:0', 'cuda:0'


# Deep MAXOUT network
dmax_param:
  active: true
  label:  'DMAX'

  lossfunc: 'cross_entropy' # cross_entropy, focal_entropy
  gamma: 2 # focal_entropy exponent parameter
  optimizer: 'Adam'
  
  num_units: 8
  neurons:  30
  dropout:  0.5
  
  epochs:  200
  batch_size:  512
  learning_rate: 0.003
  device: 'auto'                # alternative 'cpu:0', 'cuda:0'


# Deep Normalizing Flow
dbnf_param:
  active: true
  label:  'DBNF'
  
  epochs: 150
  batch_size: 512
  learning_rate: 0.01
  clip_norm: 0.1
  
  patience: 20
  cooldown: 10
  early_stopping: 100
  decay:  0.5
  min_lr: 5e-4
  polyak: 0.998

  flows: 5
  layers: 0
  hidden_dim: 30
  residual: 'normal'  # choises 'none', 'normal', 'gated'
  perm: 'flip'        # flow permutation: choises 'none', 'flip', 'rand'
  
  modelname: 'null'
  start_epoch: 0
  tensorboard: 'tensorboard'
  device: 'auto'              # alternative 'cpu:0', 'cuda:0'

